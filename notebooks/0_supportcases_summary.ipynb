{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "importpackages"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "import pprint\n",
    "\n",
    "# Add a query tag to the session.\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"cortex_support_case_analysis\", \"version\":{\"major\":1, \"minor\":0}}\n",
    "\n",
    "import snowflake.snowpark.functions as F\n",
    "from IPython.display import Markdown, display\n",
    "# model=\"mixtral-8x7b\"\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "model=\"mistral-large\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e8817-0a68-4f05-8031-5232242143cf",
   "metadata": {
    "collapsed": false,
    "name": "externalstage"
   },
   "source": [
    " Setup and Load support tickets in CSV format to stage\n",
    " Then we will create a external S3 stage for the supportcases.csv file stored in a public S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51138a30-8315-4a89-8a7b-6dcab03c9578",
   "metadata": {
    "collapsed": false,
    "name": "readfromsnowparkdfreader"
   },
   "source": [
    "Use the Snowpark DataFrame Reader to read in data from the externally staged supportcases CSV file\n",
    "In setup.sql, we staged the supportcases.csv file from an external s3 bucket. Now, we can read it in.For more information on loading data, see documentation on snowflake.snowpark.DataFrameReader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c6f3a-1230-43dd-9fa3-b462002530bd",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "S3Stage"
   },
   "outputs": [],
   "source": [
    "-- Create csv format\n",
    "CREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n",
    "    SKIP_HEADER = 1 \n",
    "    TYPE = 'CSV';\n",
    "\n",
    "-- Create external stage with the csv format to stage the diamonds dataset\n",
    "CREATE STAGE IF NOT EXISTS SUPPORT_CASES_STAGE\n",
    "    FILE_FORMAT =  CSVFORMAT \n",
    "    URL = 's3://sfquickstarts/sfguide_analyzing_support_cases_using_snowflake_cortex/SUPPORT_CASES.csv';\n",
    "    \n",
    "-- Inspect content of stage\n",
    "LS @SUPPORT_CASES_STAGE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d96a1-6fc0-48e9-ba51-23e3c307add5",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "readcsv"
   },
   "outputs": [],
   "source": [
    " # Create a Snowpark DataFrame that is configured to load data from the CSV file\n",
    "# We can now infer schema from CSV files.\n",
    "support_tickets = session.read.options({\"field_delimiter\": \",\",\n",
    "                                    \"field_optionally_enclosed_by\": '\"',\n",
    "                                    \"infer_schema\": True,\n",
    "                                    \"parse_header\": True}).csv(\"@SUPPORT_CASES_STAGE\")\n",
    "\n",
    "support_tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3de27-b532-4c0c-add3-7a3689bf66e0",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "supportticketstable"
   },
   "outputs": [],
   "source": [
    "support_tickets.write.save_as_table(\"SUPPORT_CASES\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c023b5-07bc-47b4-b420-d2d0aa835c88",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "dates"
   },
   "outputs": [],
   "source": [
    "latest_date = max(support_tickets.select('DATE_CLOSED').collect())[0]\n",
    "todays_date = datetime.now()\n",
    "print(latest_date)\n",
    "print(todays_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf4225-90af-4c1d-9ab6-375712d5e1a6",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "datediff"
   },
   "outputs": [],
   "source": [
    "diff_days = (todays_date - latest_date).days - 1\n",
    "print(diff_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83736acd-f4e0-4209-8c56-8d0dd784171a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "updatedates"
   },
   "outputs": [],
   "source": [
    "session.sql(f\"\"\"\n",
    "UPDATE SUPPORT_CASES\n",
    "SET \n",
    "    DATE_CREATED = DATEADD(DAY, {diff_days}, DATE_CREATED),\n",
    "    DATE_CLOSED = DATEADD(DAY, {diff_days}, DATE_CLOSED);\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ad552-02a0-4912-a748-6ccb700d5602",
   "metadata": {
    "language": "python",
    "name": "updatetable"
   },
   "outputs": [],
   "source": [
    "support_tickets = session.table(\"SUPPORT_CASES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a20e90-c3ec-4984-a281-62d9daa5b174",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cases"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "cases_df = support_tickets.select(\n",
    "    F.concat(\n",
    "        F.lit(\"##### \\nCASE TITLE: \"), \n",
    "        F.col(\"CASE_TITLE\"), \n",
    "        F.lit(\"\\n\\nCASE DESCRIPTION: \"), \n",
    "        F.col(\"CASE_DESCRIPTION\"), \n",
    "        F.lit('\\n\\nCASE STATUS: '), \n",
    "        F.col(\"STATUS\"), \n",
    "        F.lit('\\n\\nLAST COMMENT: '),\n",
    "        F.col('LAST_UPDATE')\n",
    "    ).alias('CASE_STRING'))\n",
    "# cases_array_pd = cases_df.to_snowpark_pandas()\n",
    "# cases_array_pd\n",
    "display(Markdown(cases_df.collect()[1]['CASE_STRING'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c712d-943c-4741-bcde-fe70591eea7a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "totaltokens"
   },
   "outputs": [],
   "source": [
    "num_tokens = cases_df.select(F.array_size(F.split(F.col('CASE_STRING'), F.lit(' '))).alias('num_tokens'))\n",
    "num_tokens.agg(F.sum(F.col('num_tokens')).alias('total_words')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6661819-f1ce-4831-a677-57e9a4fd7201",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "convertsinglestr"
   },
   "outputs": [],
   "source": [
    "pandas_df = cases_df.to_pandas()\n",
    "\n",
    "# Convert the Pandas DataFrame to a single appended string\n",
    "appended_string = pandas_df.apply(lambda x: ' '.join(x.astype(str)), axis=1).str.cat(sep=' ')\n",
    "pp.pprint(appended_string[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e6ad4f-3ea5-4dc3-99b0-4c4930b726fa",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "encoderstage"
   },
   "outputs": [],
   "source": [
    "stmt1 = f'''create stage if not exists ENCODER_STAGE'''\n",
    "session.sql(stmt1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b759fa-7ee3-4a3f-a362-351699ee0a75",
   "metadata": {
    "collapsed": false,
    "name": "mk2"
   },
   "source": [
    "## Add the file to the stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f8409-9077-484b-bb76-1d9a3cba3a2f",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "tiktokencache"
   },
   "outputs": [],
   "source": [
    "-- Inspect content of stage\n",
    "LS @ENCODER_STAGE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7fd652-02a4-41fb-8e11-df8aae35f164",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "tiktokentextsplitter"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import tiktoken\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "get_result = session.file.get(\"@ENCODER_STAGE/\", \"/tmp\")\n",
    "# Load the tiktoken ssh cache \n",
    "tiktoken_cache_dir = f'/tmp/'\n",
    "os.environ[\"TIKTOKEN_CACHE_DIR\"] = tiktoken_cache_dir\n",
    "\n",
    "\n",
    "tiktokenfile = '9b5ad71b2ce5302211f9c61530b329a4922fc6a4'\n",
    "if not os.path.exists(os.path.join(tiktoken_cache_dir, tiktokenfile)):\n",
    "    raise FileNotFoundError(f\"Cache file {tiktokenfile} not found in {tiktoken_cache_dir}\")\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    encoding = tiktoken.get_encoding('cl100k_base')\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter().from_tiktoken_encoder(\n",
    "    'cl100k_base',\n",
    "    separator=\"#####\",\n",
    "    chunk_size=20000,\n",
    "    chunk_overlap=4000,\n",
    "    is_separator_regex=False,)\n",
    "\n",
    "\n",
    "texts = text_splitter.create_documents([appended_string])\n",
    "\n",
    "print(\"First 100 characters of first chunk:\", str(texts[0])[:100])\n",
    "print(\"Tokens in text:\", num_tokens_from_string(str(texts[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a91d1e-3efa-46f9-b986-1573cb7576d8",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cortexllmapi"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "import time\n",
    "import json\n",
    "\n",
    "from snowflake.cortex import Complete\n",
    "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.llms import LLM\n",
    "\n",
    "\n",
    "class CortexLLM(LLM):\n",
    "    max_retries = 1\n",
    "    retry_delay = 10\n",
    "    model = \"reka-core\"\n",
    "    \n",
    "    def _call(\n",
    "            self,\n",
    "            prompt: str,\n",
    "            stop: Optional[List[str]] = None,\n",
    "            run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "            **kwargs: Any,\n",
    "        ) -> str:\n",
    "            response = Complete(model, prompt)\n",
    "            return response\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return a dictionary of identifying parameters.\"\"\"\n",
    "        return {\n",
    "            \"model_name\": \"CustomCortexModel\",\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"cortex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f8494-94b2-4873-8b18-2c54f1231730",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "prompts"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "map_template = PromptTemplate.from_template(\"\"\"\n",
    "                                            Given the following support cases for an order, return a summary of each case.\n",
    "                                            Include details on the category of the issue, the errors or symptoms the customer noticed,\n",
    "                                            and any basic details about what the customer was looking to accomplish.\n",
    "                                            If multiple cases exist in the same category, you can group them together.\n",
    "                                            The summary will be used to understand overall case trends and causes that the team can \n",
    "                                            use to prioritize fixes and improvements.\n",
    "                                                \n",
    "                                            ### Cases ###\n",
    "                                            \n",
    "                                            {cases}\n",
    "                                                \"\"\")\n",
    "\n",
    "reduce_template = PromptTemplate.from_template(\"\"\"\n",
    "                                                Given the following set of summaries for support case reports opened for an order, \n",
    "                                                distill it into a final, consolidated and detailed summary of trends and top pain points or blockers customers have been hitting.\n",
    "                                                Prioritize issue categories that show up in multiple summaries as they are likely to be the most impactful.\n",
    "                                                Include a description of the issue, the symptoms the customer noticed, what they were trying to do, and what led them to open the case.\n",
    "                                               \n",
    "                                                ### Case Chunk Summaries ###\n",
    "                                               \n",
    "                                                {summaries} \n",
    "                                               \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c67313-1ef8-432f-ab09-88ac51a2d449",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "mapreducefunctions"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import StuffDocumentsChain, MapReduceDocumentsChain, ReduceDocumentsChain, LLMChain\n",
    "\n",
    "llm = CortexLLM(model=model, max_retries=2, retry_delay=0)\n",
    "\n",
    "\n",
    "map_chain = LLMChain(llm=llm, prompt=map_template)\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_template)\n",
    "\n",
    "combine_docs_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, \n",
    "    document_variable_name=\"summaries\"\n",
    ")\n",
    "\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=combine_docs_chain,\n",
    "    collapse_documents_chain=combine_docs_chain,\n",
    "    token_max=28000,\n",
    ")\n",
    "\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    document_variable_name=\"cases\",\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e37d9-838b-4471-bf97-573b8616fdd0",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "length"
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30090a-9f23-461c-995e-eeeddf4ac9e7",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "summary"
   },
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "import tiktoken\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/tmp/\"\n",
    "tiktoken_cache_dir = '/tmp/'\n",
    "os.environ[\"TIKTOKEN_CACHE_DIR\"] = tiktoken_cache_dir\n",
    "if not os.path.exists(tiktoken_cache_dir):\n",
    "    raise FileNotFoundError(f\"Tokenizer files not found in {tiktoken_cache_dir}\")\n",
    "\n",
    "# Load the specific encoding by name, such as 'cl100k_base'\n",
    "encoding_name = 'cl100k_base'\n",
    "tokenizer = tiktoken.get_encoding(encoding_name)\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# Use the map_reduce_chain as before\n",
    "result = map_reduce_chain.invoke(texts)\n",
    "\n",
    "# Print results\n",
    "print(result[\"intermediate_steps\"])\n",
    "print(result[\"output_text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f14cdb-fe82-41e2-aff6-2321dd06b133",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "summarytable"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import StructType, StructField, StringType, DateType, TimestampType, VariantType\n",
    "import datetime\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"datetime\", TimestampType()),\n",
    "    StructField(\"day\", DateType()),\n",
    "    StructField(\"output_text\", StringType()),\n",
    "    StructField(\"intermediate_steps\", VariantType())\n",
    "])\n",
    "\n",
    "# Current datetime and date\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date = current_datetime.date()\n",
    "\n",
    "data = [(current_datetime, current_date, result[\"output_text\"], result[\"intermediate_steps\"])]\n",
    "df = session.create_dataframe(data, schema=schema)\n",
    "\n",
    "df.write.save_as_table(\"SUPPORT_TICKET_SUMMARY\", mode=\"overwrite\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef57e60-2e8f-4889-a0d5-008203173608",
   "metadata": {
    "language": "python",
    "name": "supportticketupdate"
   },
   "outputs": [],
   "source": [
    "support_pd = support_tickets.with_column('INDEX_TEXT',\n",
    "    F.concat(\n",
    "        F.lit(\"\\n\\nCATEGORY: \"),\n",
    "        F.col(\"CATEGORY\"),\n",
    "        F.lit(\"##### \\nCASE SUBJECT: \"), \n",
    "        F.col(\"CASE_TITLE\"), \n",
    "        F.lit(\"\\n\\nCASE DESCRIPTION: \"), \n",
    "        F.col(\"CASE_DESCRIPTION\"), \n",
    "        F.lit('\\n\\nCASE STATUS: '), \n",
    "        F.col(\"STATUS\")\n",
    "    ))\n",
    "support_pd.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ff3a3-e287-4832-92c0-b2b088742a87",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "savetable"
   },
   "outputs": [],
   "source": [
    "support_pd.write.save_as_table(\"SUPPORT_CASES\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1181b-7a7b-42f9-b6ba-9a5e723c2ba2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "supportpd"
   },
   "outputs": [],
   "source": [
    "support_pd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec8343-a459-4a8e-976d-f1daa579c31a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cortexsearchservice"
   },
   "outputs": [],
   "source": [
    "session.sql(f\"\"\"CREATE OR REPLACE CORTEX SEARCH SERVICE SUPPORT_SERVICE\n",
    "ON INDEX_TEXT \n",
    "WAREHOUSE = \"SUPPORT_WH\"\n",
    "TARGET_LAG = '1 day'\n",
    "AS (\n",
    "    SELECT INDEX_TEXT, DATE_CREATED, CASE_TITLE, CASE_ID FROM SUPPORT_CASES\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaaf821-09dd-40d5-a3c2-b13459b7cf83",
   "metadata": {
    "language": "python",
    "name": "showcortexsearch"
   },
   "outputs": [],
   "source": [
    "session.sql(\"show cortex search services in schema\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
